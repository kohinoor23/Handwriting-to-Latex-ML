{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy==1.22.4","metadata":{"execution":{"iopub.status.busy":"2023-11-13T16:50:28.772514Z","iopub.execute_input":"2023-11-13T16:50:28.772900Z","iopub.status.idle":"2023-11-13T16:50:43.604811Z","shell.execute_reply.started":"2023-11-13T16:50:28.772868Z","shell.execute_reply":"2023-11-13T16:50:43.603822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nfrom skimage import io, transform\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport torch.nn as nn\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.ion()   # interactive mode","metadata":{"execution":{"iopub.status.busy":"2023-11-13T17:51:59.678200Z","iopub.execute_input":"2023-11-13T17:51:59.678557Z","iopub.status.idle":"2023-11-13T17:51:59.688582Z","shell.execute_reply.started":"2023-11-13T17:51:59.678528Z","shell.execute_reply":"2023-11-13T17:51:59.687452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation\n- Create Dataloader class\n\nNote: Working on Part (a) as of now.","metadata":{}},{"cell_type":"code","source":"class LatexFormulaDataset(Dataset):\n    \"\"\"Latex Formula Dataset: Image and Text\"\"\"\n    \n    def __init__(self, csv_file, root_dir, transform = None):\n        \"\"\"\n        Arguments:\n            csv_file (string): Path to the csv file with image name and text\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.df = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.landmarks_frame)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Returns sample of type image, textformula\n        \"\"\"\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        img_name = os.path.join(self.root_dir,\n                                self.df.iloc[idx, 0])\n        image = io.imread(img_name)\n        formula = self.df.iloc[idx, 1]\n        formula = np.array([formula], dtype=str).reshape(-1, 1)\n        sample = {'image': image, 'formula': formula}\n\n        if self.transform:\n            sample['image'] = self.transform(sample['image'])\n\n        return sample        ","metadata":{"execution":{"iopub.status.busy":"2023-11-13T17:34:51.523123Z","iopub.execute_input":"2023-11-13T17:34:51.523866Z","iopub.status.idle":"2023-11-13T17:34:51.532580Z","shell.execute_reply.started":"2023-11-13T17:34:51.523832Z","shell.execute_reply":"2023-11-13T17:34:51.531555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image processing\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224)),\n    transforms.Lambda(lambda x: x/255.0), #min-max normalisation\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-13T17:51:07.821028Z","iopub.execute_input":"2023-11-13T17:51:07.821400Z","iopub.status.idle":"2023-11-13T17:51:07.826658Z","shell.execute_reply.started":"2023-11-13T17:51:07.821371Z","shell.execute_reply":"2023-11-13T17:51:07.825542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = io.imread('/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/SyntheticData/images/100009e256.png')\nimage = np.asarray(image)\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-13T17:51:08.773240Z","iopub.execute_input":"2023-11-13T17:51:08.774305Z","iopub.status.idle":"2023-11-13T17:51:08.782964Z","shell.execute_reply.started":"2023-11-13T17:51:08.774267Z","shell.execute_reply":"2023-11-13T17:51:08.781920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#part a\ntrain_csv_path = \"/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/SyntheticData/train.csv\"\nimage_root_path = \"/kaggle/input/converting-handwritten-equations-to-latex-code/col_774_A4_2023/SyntheticData/images\"\ntrain_set = LatexFormulaDataset(train_csv_path, image_root_path, transform)\n\nprint(train_set[1]['image'])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-13T17:51:12.844235Z","iopub.execute_input":"2023-11-13T17:51:12.844970Z","iopub.status.idle":"2023-11-13T17:51:13.020102Z","shell.execute_reply.started":"2023-11-13T17:51:12.844937Z","shell.execute_reply":"2023-11-13T17:51:13.019072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoder Network\n- A CNN to encode image to more meaningful vector","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(3, 32, (5, 5))\n        self.act1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d((2,2))\n        \n        self.conv2 = nn.Conv2d(32, 64, (5, 5))\n        self.act2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d((2, 2))\n        \n        self.conv3 = nn.Conv2d(64, 128, (5, 5))\n        self.act3 = nn.ReLU()\n        self.pool3 = nn.MaxPool2d((2, 2))\n        \n        self.conv4 = nn.Conv2d(128, 256, (5, 5))\n        self.act4 = nn.ReLU()\n        self.pool4 = nn.MaxPool2d((2, 2))\n        \n        self.conv5 = nn.Conv2d(256, 512, (5, 5))\n        self.act5 = nn.ReLU()\n        self.pool5 = nn.MaxPool2d((2, 2))\n        \n        self.avg_pool = nn.AvgPool2d((3, 3))\n    \n    def forward(self, x):\n        x = self.act1(self.conv1(x))\n        x = self.pool1(x)\n        \n        x = self.act2(self.conv2(x))\n        x = self.pool2(x)\n        \n        x = self.act3(self.conv3(x))\n        x = self.pool3(x)\n        \n        x = self.act4(self.conv4(x))\n        x = self.pool4(x)\n        \n        x = self.act5(self.conv5(x))\n        x = self.pool5(x)\n        \n        x = self.avg_pool(x)\n        x = x.reshape((1, 1, 512))\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:15:50.390048Z","iopub.execute_input":"2023-11-13T18:15:50.390411Z","iopub.status.idle":"2023-11-13T18:15:50.401998Z","shell.execute_reply.started":"2023-11-13T18:15:50.390380Z","shell.execute_reply":"2023-11-13T18:15:50.401089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Vocabulary\n- https://github.com/harvardnlp/im2markup/blob/master/data/sample/images/1015942522.png","metadata":{"execution":{"iopub.status.busy":"2023-11-13T18:15:56.105734Z","iopub.execute_input":"2023-11-13T18:15:56.106481Z","iopub.status.idle":"2023-11-13T18:15:56.198416Z","shell.execute_reply.started":"2023-11-13T18:15:56.106446Z","shell.execute_reply":"2023-11-13T18:15:56.197693Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}